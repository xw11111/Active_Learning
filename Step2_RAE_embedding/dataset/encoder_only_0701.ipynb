{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf748b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import add_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d0126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       bead1 bead2 bead3 bead4 bead5  charge1  charge2  charge3  charge4  \\\n",
      "0        C1  SQ3p    N2   N4a    N6        0        1      0.0      0.0   \n",
      "1        C1  SQ3p    N2    N6    N6        0        1      0.0      0.0   \n",
      "2        C1  SQ3p   N1a    N6    N6        0        1      0.0      0.0   \n",
      "3        C1  SQ3p   N1a   N4a    N6        0        1      0.0      0.0   \n",
      "4        C1  SQ3p   N3r   N3r    N6        0        1      0.0      0.0   \n",
      "...     ...   ...   ...   ...   ...      ...      ...      ...      ...   \n",
      "12119    C1    N6  SQ2p   NaN   NaN        0        0      1.0      NaN   \n",
      "12120    C1    N6    Q2   NaN   NaN        0        0      1.0      NaN   \n",
      "12121    C1    N6    Q5   NaN   NaN        0        0     -1.0      NaN   \n",
      "12122    C1  SQ3p   NaN   NaN   NaN        0        1      NaN      NaN   \n",
      "12123    C1  SQ2p   NaN   NaN   NaN        0        1      NaN      NaN   \n",
      "\n",
      "       charge5  ...  label_NM5 label_HB5 label_PN5 label_SI5 label_SZ5  \\\n",
      "0          0.0  ...         N6      none      none      none         R   \n",
      "1          0.0  ...         N6      none      none      none         R   \n",
      "2          0.0  ...         N6      none      none      none         R   \n",
      "3          0.0  ...         N6      none      none      none         R   \n",
      "4          0.0  ...         N6      none      none      none         R   \n",
      "...        ...  ...        ...       ...       ...       ...       ...   \n",
      "12119      NaN  ...        NaN       NaN       NaN       NaN       NaN   \n",
      "12120      NaN  ...        NaN       NaN       NaN       NaN       NaN   \n",
      "12121      NaN  ...        NaN       NaN       NaN       NaN       NaN   \n",
      "12122      NaN  ...        NaN       NaN       NaN       NaN       NaN   \n",
      "12123      NaN  ...        NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "      delta_G1 delta_G2 delta_G3 delta_G4 delta_G5  \n",
      "0         17.2    -47.8      0.5     -5.0     -9.8  \n",
      "1         17.2    -47.8      0.5     -9.8     -9.8  \n",
      "2         17.2    -47.8      2.9     -9.8     -9.8  \n",
      "3         17.2    -47.8      2.9     -5.0     -9.8  \n",
      "4         17.2    -47.8     -3.6     -3.6     -9.8  \n",
      "...        ...      ...      ...      ...      ...  \n",
      "12119     17.2     -9.8    -43.3      NaN      NaN  \n",
      "12120     17.2     -9.8    -32.7      NaN      NaN  \n",
      "12121     17.2     -9.8    -64.1      NaN      NaN  \n",
      "12122     17.2    -47.8      NaN      NaN      NaN  \n",
      "12123     17.2    -43.3      NaN      NaN      NaN  \n",
      "\n",
      "[12124 rows x 41 columns]>\n"
     ]
    }
   ],
   "source": [
    "origin_df = pd.read_csv('features.csv')\n",
    "print(origin_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44ab1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bead1', 'bead2', 'bead3', 'bead4', 'bead5', 'charge1', 'charge2',\n",
      "       'charge3', 'charge4', 'charge5',\n",
      "       ...\n",
      "       'label_SZ1_R', 'label_SZ1_S', 'label_SZ2_R', 'label_SZ2_S',\n",
      "       'label_SZ3_R', 'label_SZ3_S', 'label_SZ4_R', 'label_SZ4_S',\n",
      "       'label_SZ5_R', 'label_SZ5_S'],\n",
      "      dtype='object', length=151)\n"
     ]
    }
   ],
   "source": [
    "max_beads = 5\n",
    "origin_df.replace('none', np.nan, inplace=True)\n",
    "all_types_NM = ['N1', 'N2', 'N3', 'N4', 'N5', 'N6',\n",
    "                'P1', 'P2', 'P3', 'P4', 'P5', 'P6', \n",
    "                'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'D',\n",
    "                'C1']\n",
    "all_types_HB = ['a', 'd']\n",
    "all_types_PN = ['p', 'n']\n",
    "all_types_SI = ['r', 'h']\n",
    "all_types_SZ = ['S', 'R']\n",
    "\n",
    "\n",
    "label_NM = [f'label_NM{i}' for i in range(1, max_beads+1)]\n",
    "label_HB = [f'label_HB{i}' for i in range(1, max_beads+1)]\n",
    "label_PN = [f'label_PN{i}' for i in range(1, max_beads+1)]\n",
    "label_SI = [f'label_SI{i}' for i in range(1, max_beads+1)]\n",
    "label_SZ = [f'label_SZ{i}' for i in range(1, max_beads+1)]\n",
    "\n",
    "def one_hot_encode_column(column, all_categories):\n",
    "    dummies = pd.get_dummies(column, prefix=column.name)\n",
    "    # Reindex to ensure all categories are included, filling with 0s\n",
    "    for category in all_categories:\n",
    "        col_name = f\"{column.name}_{category}\"\n",
    "        if col_name not in dummies.columns:\n",
    "            dummies[col_name] = 0\n",
    "    return dummies\n",
    "\n",
    "# Create a copy of the dataframe to modify\n",
    "encoded_df = origin_df.copy()\n",
    "\n",
    "# one-hot encoding\n",
    "for col in label_NM:\n",
    "    encoded_dummies = one_hot_encode_column(encoded_df[col], all_types_NM)\n",
    "    encoded_df = encoded_df.drop(columns=[col]).join(encoded_dummies)\n",
    "\n",
    "for col in label_HB:\n",
    "    encoded_dummies = one_hot_encode_column(encoded_df[col], all_types_HB)\n",
    "    encoded_df = encoded_df.drop(columns=[col]).join(encoded_dummies)\n",
    "\n",
    "for col in label_PN:\n",
    "    encoded_dummies = one_hot_encode_column(encoded_df[col], all_types_PN)\n",
    "    encoded_df = encoded_df.drop(columns=[col]).join(encoded_dummies)\n",
    "\n",
    "for col in label_SI:\n",
    "    encoded_dummies = one_hot_encode_column(encoded_df[col], all_types_SI)\n",
    "    encoded_df = encoded_df.drop(columns=[col]).join(encoded_dummies)\n",
    "\n",
    "for col in label_SZ:\n",
    "    encoded_dummies = one_hot_encode_column(encoded_df[col], all_types_SZ)\n",
    "    encoded_df = encoded_df.drop(columns=[col]).join(encoded_dummies)\n",
    "\n",
    "\n",
    "print(encoded_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d7434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12124 30\n"
     ]
    }
   ],
   "source": [
    "#replace all nan with 0 (charge & delta_G)\n",
    "encoded_df.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "df = encoded_df.copy()\n",
    "df = df.drop(columns=['bead1','bead2','bead3','bead4', 'bead5'])\n",
    "num_compounds = len(df)    #k\n",
    "num_features = int(len(df.drop(columns=['net_charge']).columns)/max_beads+1)   #i\n",
    "print(num_compounds, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebd5821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12124, 30), (12124, 30), (12124, 30), (12124, 30), (12124, 30)]\n",
      "(12124, 30, 5)\n"
     ]
    }
   ],
   "source": [
    "#N\n",
    "columns = ['charge', 'delta_G', 'label_NM', 'label_HB', 'label_PN', 'label_SI', 'label_SZ']\n",
    "arrays = {}\n",
    "for i in range(1, max_beads+1):\n",
    "    charge = [f'charge{i}']\n",
    "    delta_G = [f'delta_G{i}']\n",
    "    label_NM = [f'label_NM{i}_{j}' for j in all_types_NM]\n",
    "    label_HB = [f'label_HB{i}_{j}' for j in all_types_HB]\n",
    "    label_PN = [f'label_PN{i}_{j}' for j in all_types_PN]\n",
    "    label_SI = [f'label_SI{i}_{j}' for j in all_types_SI]\n",
    "    label_SZ = [f'label_SZ{i}_{j}' for j in all_types_SZ]\n",
    "    net_charge = [f'net_charge']\n",
    "    arrays[f'array_{i}'] = df[charge + delta_G + label_NM + label_HB + label_PN + label_SI + label_SZ + net_charge].values\n",
    "\n",
    "array_1, array_2, array_3, array_4, array_5= arrays['array_1'], arrays['array_2'], arrays['array_3'], arrays['array_4'], arrays['array_5']\n",
    "\n",
    "# Check the shapes of the arrays\n",
    "print([array.shape for array in [array_1, array_2, array_3, array_4, array_5]])\n",
    "\n",
    "N = np.stack([array_1, array_2, array_3, array_4, array_5], axis = -1)\n",
    "print(N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "036e24bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12124, 5, 5)\n",
      "[[1 1 0 0 0]\n",
      " [1 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#A\n",
    "def create_adjacency_matrix(beads, max_beads=5):\n",
    "    matrix = np.zeros((max_beads, max_beads), dtype=int)\n",
    "\n",
    "    if num_beads > 0:\n",
    "        np.fill_diagonal(matrix[:num_beads, :num_beads], 1)\n",
    "\n",
    "        for i in range(num_beads - 1):\n",
    "            matrix[i, i + 1] = 1\n",
    "            matrix[i + 1, i] = 1\n",
    "\n",
    "    return matrix\n",
    "\n",
    "A = []\n",
    "\n",
    "for _, row in origin_df.iterrows():\n",
    "    beads = [row[f'bead{i}'] for i in range(1, 6)]\n",
    "    num_beads = sum(pd.notna(beads))\n",
    "    adjacency_matrix = create_adjacency_matrix(beads)\n",
    "    A.append(adjacency_matrix)\n",
    "    \n",
    "A=np.array(A)\n",
    "print(A.shape)\n",
    "print(A[12123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe3d3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12124, 5, 5) (12124, 5, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.47 , 0.443, 0.   , 0.   , 0.   ],\n",
       "        [0.443, 0.41 , 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , 0.   , 0.   ]]),\n",
       " array([[3.39 , 2.464, 0.   , 0.   , 0.   ],\n",
       "        [2.464, 2.52 , 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , 0.   , 0.   ]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Edge\n",
    "itp_file_path = 'martini_v3.0.0 1.itp'\n",
    "itp_data = pd.read_csv(itp_file_path, delim_whitespace=True, header=None)\n",
    "sigma_dict = {}\n",
    "epsilon_dict = {}\n",
    "\n",
    "for _, row in itp_data.iterrows():\n",
    "    bead1, bead2, _, sigma, epsilon = row\n",
    "    pair = (bead1, bead2)\n",
    "    sigma_dict[pair] = sigma\n",
    "    epsilon_dict[pair] = epsilon\n",
    "\n",
    "def generate_edge(row, sigma_dict, epsilon_dict):\n",
    "    beads = [row['bead1'], row['bead2'], row['bead3'], row['bead4'], row['bead5']]\n",
    "    sigma_tensor = np.zeros((max_beads, max_beads))\n",
    "    epsilon_tensor = np.zeros((max_beads, max_beads))\n",
    "    \n",
    "    for i in range(max_beads):\n",
    "        for j in range(max_beads):\n",
    "            if pd.notna(beads[i]) and pd.notna(beads[j]):\n",
    "                pair = (beads[i], beads[j])\n",
    "                # Use get() with reversed pair as well to handle both (bead1, bead2) and (bead2, bead1)\n",
    "                sigma_tensor[i, j] = sigma_dict.get(pair, sigma_dict.get((beads[j], beads[i]), 0))\n",
    "                epsilon_tensor[i, j] = epsilon_dict.get(pair, epsilon_dict.get((beads[j], beads[i]), 0))\n",
    "    \n",
    "    return sigma_tensor, epsilon_tensor\n",
    "\n",
    "# Generate tensors for each row \n",
    "sigma_tensors = []\n",
    "epsilon_tensors = []\n",
    "\n",
    "for _, row in origin_df.iterrows():\n",
    "    sigma_tensor, epsilon_tensor = generate_edge(row, sigma_dict, epsilon_dict)\n",
    "    sigma_tensors.append(sigma_tensor)\n",
    "    epsilon_tensors.append(epsilon_tensor)\n",
    "\n",
    "sigma_tensors = np.array(sigma_tensors)\n",
    "epsilon_tensors = np.array(epsilon_tensors)\n",
    "\n",
    "print(sigma_tensors.shape, epsilon_tensors.shape)\n",
    "sigma_tensors[-1], epsilon_tensors[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895972c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('N.npy', N)\n",
    "np.save('A.npy', A)\n",
    "np.save('sigma.npy', sigma_tensors)\n",
    "np.save('epsilon.npy', epsilon_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e46b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.tensor(np.load('N.npy'), dtype=torch.float)\n",
    "A = torch.tensor(np.load('A.npy'), dtype=torch.float)\n",
    "sigma = torch.tensor(np.load('sigma.npy'), dtype=torch.float)\n",
    "epsilon = torch.tensor(np.load('epsilon.npy'), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e19843a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MPNN works well for the multi-dimensional edge features,while GNN does not\n",
    "#Transformer is also a good choice for the sequence, where the edges can be treated as node features\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, node_in_features, node_out_features, edge_features):\n",
    "        super(MPNNLayer, self).__init__(aggr='add')\n",
    "        self.node_lin = torch.nn.Linear(node_in_features, node_out_features)\n",
    "        self.edge_lin = torch.nn.Linear(edge_features, node_out_features)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x has shape [N, node_in_features]\n",
    "        # edge_index has shape [2, E]\n",
    "        # edge_attr has shape [E, edge_features]\n",
    "        edge_out = self.edge_lin(edge_attr)\n",
    "        return self.propagate(edge_index, x=self.node_lin(x), edge_attr=edge_out)\n",
    "    \n",
    "    def message(self, x_j, edge_attr):\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "# Define the MPNN Encoder\n",
    "class MPNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, node_in_features, node_out_features, edge_features, latent_dim):\n",
    "        super(MPNNEncoder, self).__init__()\n",
    "        self.mpnn1 = MPNNLayer(node_in_features, node_out_features, edge_features)\n",
    "        self.mpnn2 = MPNNLayer(node_out_features, latent_dim, edge_features)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.mpnn1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.mpnn2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "# Prepare the dataset\n",
    "def create_data_objects(N, A, sigma, epsilon):\n",
    "    data_list = []\n",
    "    for i in range(N.shape[0]):\n",
    "        edge_index = torch.nonzero(A[i]).t().contiguous()\n",
    "        edge_attr = torch.stack((sigma[i][A[i] == 1], epsilon[i][A[i] == 1]), dim=-1)\n",
    "        data = Data(x=N[i], edge_index=edge_index, edge_attr=edge_attr)\n",
    "        data_list.append(data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3144e2ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m create_data_objects(N, A, sigma, epsilon)\n\u001b[0;32m      2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m MPNNEncoder(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m, in \u001b[0;36mMPNNEncoder.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m---> 30\u001b[0m     x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[0;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmpnn1(x, edge_index, edge_attr)\n\u001b[0;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "data = create_data_objects(N, A, sigma, epsilon)\n",
    "encoder = MPNNEncoder(30, 128, 2, 16)\n",
    "encoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888f1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
